#version: '3.8'

include:
  - path:
    - rag_service/docker-compose.yaml
services:
  redis:
    image: redis:alpine
    platform: linux/amd64
    container_name: redis
    ports:
      - "6379:6379"

  gpt-4-mini:
    build: ./inference_service
    container_name: inference_service_gpt4mini
    ports:
      - "8002:8000"
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      MODEL_NAME: "gpt-4o-mini"

  gpt-4o:
    build: ./inference_service
    container_name: inference_service_gpt4o
    ports:
      - "8003:8000"
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      MODEL_NAME: "gpt-4o"

  llama-3.1:
    build: ./inference_service
    container_name: inference_service_llama
    ports:
      - "8004:8000"
    environment:
      BASE_URL: "https://api.studio.nebius.ai/v1/"
      OPENAI_API_KEY: ${NEBIUS_API_KEY}
      MODEL_NAME: "meta-llama/Meta-Llama-3.1-70B-Instruct"

  gateway_service:
    build: ./gateway_service
    container_name: gateway_service
    ports:
      - "8001:8001"
    depends_on:
      - redis
      - gpt-4-mini
      - gpt-4o
      - llama-3.1
      - postgres
      - rag_service
    environment:
      ADMIN_KEY: ${ADMIN_KEY}

  postgres:
    image: postgres:13
    platform: linux/amd64
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: dbname
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  rag_gradio_service:
    build: ./rag_gradio_service
    container_name: rag_gradio_service
    ports:
      - "7860:7860"

volumes:
  postgres_data:
    driver: local
